# -*- coding: utf-8 -*-
"""nlp-spam-detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LK6hXtuuucypGFSlUrQri7zzgQ-0U6W8

**"Classifying Spam Messages with NLP & ML"**

**Intro - Spam detection is a common NLP problem where we classify messages as either Spam or Not Spam (Ham). This project explores how machine learning models can be used to detect spam messages effectively.**

**Description - spam detection  (/kaggle/input/spam-detection/spam.csv).Key features ( "text" column for messages, "label" column for spamORham).**
"""

#data discover
import pandas as pd
import re
import nltk
df=pd.read_csv('/kaggle/input/spam-detection/spam.csv')
df.head()

##check nulls
print(f"nulls in df:",df.isnull().sum())
print(f"duplication in data are:",df.duplicated().any())

df.rename(columns={'Unnamed: 0': 'id'}, inplace=True)
df.head()

##removing unwanted charact

def clean_text(text):
    # Remove unwanted characters (e.g., punctuation, special characters)
    text = re.sub(r"[^a-zA-Z0-9\s']", '', text)
    # Convert to lowercase for uniformity
    text = text.lower()
    return text
df['Message'] = df['Message'].apply(clean_text)

from nltk.tokenize import word_tokenize

nltk.download('punkt')
df['tokens'] = df['Message'].apply(word_tokenize)
df.head()

#remove stopwords
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import nltk

nltk.download('stopwords', download_dir='/your/custom/directory')

stop_words = set(stopwords.words('english'))

def remove_stop_words(tokens):
    return [word for word in tokens if word.lower() not in stop_words]
df['clean_tokens'] = df['tokens'].apply(remove_stop_words)

#encode spamORham col
from sklearn.preprocessing import LabelEncoder

# Encode the labels
label_encoder = LabelEncoder()
df['spamORham'] = label_encoder.fit_transform(df['spamORham'])
print(df['spamORham'].head())

import spacy

# Load the SpaCy English model
nlp = spacy.load('en_core_web_sm')

# Lemmatization function using SpaCy
def spacy_lemmatize(tokens):
    doc = nlp(" ".join(tokens))  # Convert tokens back to a single string
    return [token.lemma_ for token in doc]

# Apply the lemmatization to the 'clean_tokens' column
df['lemmatized_tokens'] = df['clean_tokens'].apply(spacy_lemmatize)

# Combine lemmatized tokens back into a single string
df['final_text'] = df['lemmatized_tokens'].apply(lambda tokens: " ".join(tokens))

X = df['final_text']
y = df['spamORham']

from sklearn.feature_extraction.text import TfidfVectorizer

# Initialize TF-IDF Vectorizer
vectorizer = TfidfVectorizer()

# Fit and transform the text data
X_vectorized = vectorizer.fit_transform(X)

"""
**Results and AnalysisAfter training the Multinomial Naïve Bayes model on the spam detection dataset, we evaluated its performance using a classification report and a confusion matrix.**


**Classification ReportThe classification report provides precision, recall, F1-score, and support for each class:**
"""

# Start with raw data
X = df['final_text']
y = df['spamORham']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

from sklearn.naive_bayes import MultinomialNB
model = MultinomialNB()
model.fit(X_train_vec, y_train)

y_pred = model.predict(X_test_vec)

results_df = pd.DataFrame({
    "Message": X_test.values,
    "Actual Label": y_test.values,
    "Predicted Label": y_pred
})

# View results
print(results_df.head(10))

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

"""The confusion matrix shows the model's performance in terms of correctly and incorrectly classified messages:



"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred, labels=[0, 1])  # 0 = ham, 1 = spam

# Visualize the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Ham", "Spam"])
disp.plot(cmap="Blues")
plt.title("Confusion Matrix")
plt.show()

def predict_message(message):
    transformed = vectorizer.transform([message])
    return model.predict(transformed)[0]

import joblib
joblib.dump(model, "spam_detector_model.pkl")

"""
**Conclusion and Future WorkIn this project, we built a spam detection model using Multinomial Naïve Bayes. The model performed well, achieving high accuracy and good classification metrics. However, there are areas for improvement.**
"""